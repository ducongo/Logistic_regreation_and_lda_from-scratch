# -*- coding: utf-8 -*-
"""assignment1clean

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bBBFAD704YdLDCtpCwh2uVNVYSvgOSCb
"""

import numpy as np

class LogisticRegression:
    def __init__(self, learningRate=0.1, num_iter=10000):
        self.gradient_descent = []
        self.learningRate = learningRate
        self.num_iter = num_iter
        self.fit_intercept = True
        
    
    
    def __sigmoid(self, z):
        return 1 / (1 + np.exp(-z))

    def _logisticLoss(self, h, y):
        return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()

    def _intercept(self, X):
        intercept = np.ones((X.shape[0], 1))
        return np.concatenate((intercept, X), axis=1)
    
    def fit(self, X, y):
        if self.fit_intercept:
            X = self._intercept(X)
        
        # weights initialization
        self.weights = np.zeros(X.shape[1])
        
        for i in range(self.num_iter):
            h = self.__sigmoid(np.dot(X, self.weights))
            gradient = np.dot(X.T, (h - y)) * (1/y.size)
            self.weights = self.weights - self.learningRate * gradient
            self.gradient_descent.append(gradient)
        
        h = self.__sigmoid(np.dot(X, self.weights))
        loss = self._logisticLoss(h, y)
        print(f'loss : {loss}')

        return self._logisticLoss(h, y)
        
    def predict(self, X, threshold):
        prediction = False
        if self.fit_intercept == True:
            X = self._intercept(X)
        predictions = self.__sigmoid(np.dot(X, self.weights))
        predictions[predictions >= threshold] = 1
        predictions[predictions < threshold] = 0
        return predictions

    def accu_eval(self, predicted, true_value):
        accur = np.zeros(predicted.shape)
        accur[predicted == true_value] = 1
        return (sum(accur) / accur.shape[0]) * 100


